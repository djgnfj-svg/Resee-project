# ë°±ì—”ë“œ ê°œì„  ê³¼ì œ - Resee Project

> ì·¨ì—…/ì´ë ¥ì„œì— ìœ ë¦¬í•œ ê¸°ìˆ ì  ê°œì„  ì‚¬í•­ 8ê°€ì§€

---

## ğŸ“Š í˜„ì¬ ì•„í‚¤í…ì²˜ ê°•ì 

- âœ… LangChain + LangGraph ê¸°ë°˜ AI ì‹œìŠ¤í…œ
- âœ… Celery ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬
- âœ… Redis Rate Limiting
- âœ… Service Layer íŒ¨í„´
- âœ… DB ì¸ë±ìŠ¤ ìµœì í™”

---

## ğŸ¯ ê°œì„  ê³¼ì œ (ìš°ì„ ìˆœìœ„ìˆœ)

### 1. Redis Write-Behind ìºì‹± íŒ¨í„´ â­â­â­

**ë¬¸ì œì :**
- `CategoryReviewStatsView`, `DashboardStatsView`ì—ì„œ ë§¤ ìš”ì²­ë§ˆë‹¤ ë³µì¡í•œ ì§‘ê³„ ì¿¼ë¦¬
- 30ì¼ ì„±ê³µë¥  ê³„ì‚° ì‹œ DB ë¶€í•˜

**ì†”ë£¨ì…˜:**
```python
# Write-Behind: ì“°ê¸°ëŠ” ì¦‰ì‹œ ìºì‹œ â†’ ë¹„ë™ê¸°ë¡œ DB ë°˜ì˜
class RedisWriteBehindCache:
    def update_stats(self, user_id, data):
        # 1. Redisì— ì¦‰ì‹œ ì €ì¥
        cache.set(f'stats:{user_id}', data, timeout=3600)

        # 2. Celeryë¡œ ë¹„ë™ê¸° DB ì €ì¥
        sync_stats_to_db.delay(user_id, data)

# Celery ì£¼ê¸° ì‘ì—…ìœ¼ë¡œ í†µê³„ ì‚¬ì „ ê³„ì‚°
@periodic_task(run_every=crontab(minute='*/15'))
def precompute_user_statistics():
    for user in active_users:
        stats = calculate_stats(user)
        cache.set(f'stats:{user.id}', stats)
```

**ê¸°ëŒ€ íš¨ê³¼:**
- API ì‘ë‹µ ì‹œê°„: 500ms â†’ 75ms (85% ê°œì„ )
- DB ë¶€í•˜: 60% ê°ì†Œ

**ì´ë ¥ì„œ í‘œí˜„:**
- "Redis Write-Behind ìºì‹±ìœ¼ë¡œ í†µê³„ ì¿¼ë¦¬ ì‘ë‹µì†ë„ 85% ê°œì„ "
- "Celery ì£¼ê¸° ì‘ì—…ìœ¼ë¡œ DB ë¶€í•˜ 60% ê°ì†Œ"

---

### 2. CQRS íŒ¨í„´ (Read/Write ë¶„ë¦¬) â­â­â­

**ë¬¸ì œì :**
- `ReviewHistory` í…Œì´ë¸”ì— ì½ê¸°/ì“°ê¸° í˜¼ì¬
- í†µê³„ ì¡°íšŒ ì‹œ íŠ¸ëœì­ì…˜ í…Œì´ë¸” ì§ì ‘ ìŠ¤ìº”

**ì†”ë£¨ì…˜:**
```python
# Command: ì“°ê¸° (ì •ê·œí™”)
class ReviewHistoryCommand:
    def record_review(self, user, content, result):
        ReviewHistory.objects.create(...)
        update_review_statistics.delay(user.id)  # Event ë°œí–‰

# Query: ì½ê¸° (ë¹„ì •ê·œí™”, ì½ê¸° ìµœì í™”)
class ReviewStatisticsReadModel(models.Model):
    user = models.ForeignKey(User)
    total_reviews = models.IntegerField()
    success_rate = models.FloatField()
    last_updated = models.DateTimeField()

    class Meta:
        db_table = 'review_statistics_readonly'
```

**ê¸°ëŒ€ íš¨ê³¼:**
- í†µê³„ ì¡°íšŒ ì„±ëŠ¥: 3ë°° í–¥ìƒ
- ë³µì¡í•œ JOIN ì œê±°

**ì´ë ¥ì„œ í‘œí˜„:**
- "CQRS íŒ¨í„´ ë„ì…ìœ¼ë¡œ Read/Write ë¶„ë¦¬, í†µê³„ ì¡°íšŒ ì„±ëŠ¥ 3ë°° í–¥ìƒ"

---

### 3. LangGraph Agent Memory ì‹œìŠ¤í…œ â­â­â­

**ë¬¸ì œì :**
- AI í‰ê°€ ì‹œ ì´ì „ ì»¨í…ìŠ¤íŠ¸ ë¯¸í™œìš©
- ì‚¬ìš©ìë³„ í•™ìŠµ íŒ¨í„´ ë¶„ì„ ë¶€ì¬

**ì†”ë£¨ì…˜:**
```python
from langchain.memory import RedisChatMessageHistory

class UserLearningMemory:
    def __init__(self, user_id):
        self.memory = RedisChatMessageHistory(
            session_id=f"user:{user_id}",
            url=settings.REDIS_URL,
            ttl=86400 * 30
        )

    def get_personalized_feedback(self, content):
        chain = ConversationChain(llm=llm, memory=self.memory)
        return chain.predict(input=f"í‰ê°€: {content}")
```

**ê¸°ëŒ€ íš¨ê³¼:**
- ê°œì¸í™”ëœ AI í”¼ë“œë°±
- í•™ìŠµ íŒ¨í„´ ê¸°ë°˜ ì¶”ì²œ

**ì´ë ¥ì„œ í‘œí˜„:**
- "LangChain Memory + Redisë¡œ ì‚¬ìš©ìë³„ AI í•™ìŠµ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬"
- "ê°œì¸í™”ëœ í”¼ë“œë°±ìœ¼ë¡œ í•™ìŠµ ë§Œì¡±ë„ 40% í–¥ìƒ"

---

### 4. Circuit Breaker íŒ¨í„´ (AI API ì•ˆì •ì„±) â­â­

**ë¬¸ì œì :**
- AI API ì¥ì•  ì‹œ ë°˜ë³µ í˜¸ì¶œë¡œ ë¦¬ì†ŒìŠ¤ ë‚­ë¹„
- Fallbackë§Œ ì¡´ì¬, ì¥ì•  ê²©ë¦¬ ì—†ìŒ

**ì†”ë£¨ì…˜:**
```python
from circuitbreaker import circuit

class AIServiceCircuitBreaker:
    @circuit(failure_threshold=5, recovery_timeout=30)
    def call_ai_api(self, prompt):
        try:
            return ai_service.invoke(prompt)
        except Exception:
            raise

    def fallback_response(self):
        return get_cached_similar_response()
```

**ê¸°ëŒ€ íš¨ê³¼:**
- API ì‹¤íŒ¨ìœ¨: 95% ê°ì†Œ
- ì‚¬ìš©ì ê²½í—˜ ì•ˆì •ì„± í™•ë³´

**ì´ë ¥ì„œ í‘œí˜„:**
- "Circuit Breaker íŒ¨í„´ìœ¼ë¡œ ì™¸ë¶€ AI API ì¥ì•  ê²©ë¦¬"

---

### 5. N+1 Query ìµœì í™” â­â­

**ë¬¸ì œì :**
- `CategoryReviewStatsView`ì—ì„œ ë°˜ë³µ ì¿¼ë¦¬ ê°€ëŠ¥ì„±
- Serializerì—ì„œ ì¶”ê°€ ì¿¼ë¦¬ ë°œìƒ

**ì†”ë£¨ì…˜:**
```python
class OptimizedReviewScheduleViewSet(viewsets.ModelViewSet):
    def get_queryset(self):
        return ReviewSchedule.objects.filter(
            user=self.request.user
        ).select_related(
            'content', 'content__category', 'user'
        ).prefetch_related(
            Prefetch('content__review_histories', ...)
        ).annotate(
            success_count=Count(...),
            total_reviews=Count(...)
        )
```

**ê¸°ëŒ€ íš¨ê³¼:**
- API ì‘ë‹µ ì‹œê°„: 70% ë‹¨ì¶•
- ì¿¼ë¦¬ ìˆ˜: 15ê°œ â†’ 3ê°œ

**ì´ë ¥ì„œ í‘œí˜„:**
- "Django ORM N+1 ë¬¸ì œ í•´ê²°ë¡œ API ì‘ë‹µ ì‹œê°„ 70% ë‹¨ì¶•"

---

### 6. Celery Priority Queue â­â­

**ë¬¸ì œì :**
- ë‹¨ì¼ íë¡œ ëª¨ë“  ì‘ì—… ì²˜ë¦¬
- ì¤‘ìš” ì‘ì—…(ì´ë©”ì¼)ê³¼ ì¼ë°˜ ì‘ì—…(ë¬¸ì œ ìƒì„±) ìš°ì„ ìˆœìœ„ ë¯¸ë¶„ë¦¬

**ì†”ë£¨ì…˜:**
```python
# celery.py
app.conf.task_routes = {
    'accounts.email.tasks.*': {'queue': 'high_priority'},
    'exams.tasks.*': {'queue': 'low_priority'},
    'review.tasks.*': {'queue': 'medium_priority'},
}

# Task Retry ì „ëµ
@shared_task(
    bind=True,
    max_retries=3,
    retry_backoff=True,
    retry_backoff_max=600,
    retry_jitter=True
)
def robust_ai_task(self, content_id):
    pass
```

**ê¸°ëŒ€ íš¨ê³¼:**
- ì¤‘ìš” ì‘ì—… ì²˜ë¦¬ ì‹œê°„: 50% ë‹¨ì¶•
- Exponential Backoffë¡œ ì¬ì‹œë„ ìµœì í™”

**ì´ë ¥ì„œ í‘œí˜„:**
- "Celery Priority Queueë¡œ ì‘ì—… ìš°ì„ ìˆœìœ„ ê´€ë¦¬"
- "Exponential Backoff + Jitterë¡œ ì¬ì‹œë„ ì „ëµ ê°œì„ "

---

### 7. PostgreSQL Materialized View â­â­

**ë¬¸ì œì :**
- `CategoryReviewStatsView`ì—ì„œ ì‹¤ì‹œê°„ ì§‘ê³„
- 30ì¼ ë¦¬ë·° íˆìŠ¤í† ë¦¬ ë§¤ë²ˆ ê³„ì‚°

**ì†”ë£¨ì…˜:**
```sql
-- Materialized View ìƒì„±
CREATE MATERIALIZED VIEW review_category_stats AS
SELECT
    u.id as user_id,
    c.id as category_id,
    COUNT(DISTINCT cnt.id) as total_content,
    ROUND(AVG(CASE
        WHEN rh.result = 'remembered' THEN 100
        ELSE 0
    END), 1) as success_rate
FROM accounts_user u
LEFT JOIN review_reviewhistory rh ON ...
GROUP BY u.id, c.id;

-- Celeryë¡œ ì£¼ê¸°ì  refresh
@periodic_task(run_every=crontab(minute='*/10'))
def refresh_review_statistics():
    execute("REFRESH MATERIALIZED VIEW CONCURRENTLY review_category_stats")
```

**ê¸°ëŒ€ íš¨ê³¼:**
- ë³µì¡í•œ í†µê³„ ì¿¼ë¦¬: 95% ì„±ëŠ¥ í–¥ìƒ
- ì¿¼ë¦¬ ì‹œê°„: 2000ms â†’ 50ms

**ì´ë ¥ì„œ í‘œí˜„:**
- "PostgreSQL Materialized Viewë¡œ í†µê³„ ì¿¼ë¦¬ 95% ì„±ëŠ¥ í–¥ìƒ"

---

### 8. Redis Pub/Sub Event-Driven Architecture â­

**ë¬¸ì œì :**
- Signal ê¸°ë°˜ ì´ë²¤íŠ¸ ì²˜ë¦¬ë§Œ ì¡´ì¬
- ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í™•ì¥ì„± ì œí•œ

**ì†”ë£¨ì…˜:**
```python
# Event Publisher
class DomainEventPublisher:
    def publish(self, event_type, data):
        redis_client.publish(
            f'events:{event_type}',
            json.dumps(data)
        )

# Event Handler
@shared_task
def subscribe_to_events():
    pubsub = redis_client.pubsub()
    pubsub.subscribe('events:review_completed')

    for message in pubsub.listen():
        handle_event(json.loads(message['data']))
```

**ê¸°ëŒ€ íš¨ê³¼:**
- ì„œë¹„ìŠ¤ ê°„ ëŠìŠ¨í•œ ê²°í•©
- ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì „í™˜

**ì´ë ¥ì„œ í‘œí˜„:**
- "Redis Pub/Sub ê¸°ë°˜ Event-Driven Architecture ì„¤ê³„"

---

## ğŸ† TOP 3 ì¶”ì²œ (ì´ë ¥ì„œ ì„íŒ©íŠ¸ ê¸°ì¤€)

### 1ìˆœìœ„: Redis Write-Behind + CQRS (2-3ì£¼)
- ì„±ëŠ¥ ê°œì„  ìˆ˜ì¹˜í™” ê°€ëŠ¥
- ëŒ€ìš©ëŸ‰ íŠ¸ë˜í”½ ëŒ€ë¹„ ê²½í—˜
- ì‹¤ë¬´ í•„ìˆ˜ íŒ¨í„´

### 2ìˆœìœ„: LangChain Memory + Circuit Breaker (1-2ì£¼)
- AI ì„œë¹„ìŠ¤ ì•ˆì •ì„± ê°•í™”
- ìµœì‹  ê¸°ìˆ  ìŠ¤íƒ
- ì¥ì•  ëŒ€ì‘ ì—­ëŸ‰ ì¦ëª…

### 3ìˆœìœ„: Materialized View + Priority Queue (1ì£¼)
- DB ìµœì í™” ì‹¤ë ¥ ì¦ëª…
- ë¹„ë™ê¸° ì‘ì—… ê´€ë¦¬ ì—­ëŸ‰
- ì‹œìŠ¤í…œ ì„¤ê³„ ì´í•´ë„

---

## ğŸ“ˆ ì¸¡ì • ì§€í‘œ

### êµ¬í˜„ ì „/í›„ ë¹„êµ
```
- API ì‘ë‹µ ì‹œê°„: 500ms â†’ 100ms (80% ê°œì„ )
- DB ì¿¼ë¦¬ ìˆ˜: 15ê°œ â†’ 3ê°œ (80% ê°ì†Œ)
- ìºì‹œ íˆíŠ¸ìœ¨: 0% â†’ 85%
- AI API ì„±ê³µë¥ : 90% â†’ 99%
```

### ëª¨ë‹ˆí„°ë§ (Prometheus)
```python
api_response_time = Histogram('api_response_seconds')
cache_hit_rate = Counter('cache_hits_total')
db_query_time = Histogram('db_query_seconds')
```

---

## ğŸ“ êµ¬í˜„ ìˆœì„œ ì¶”ì²œ

1. **Week 1-2**: Redis Write-Behind + CQRS ê¸°ë°˜ êµ¬ì¶•
2. **Week 3**: LangChain Memory + Circuit Breaker
3. **Week 4**: Materialized View + Priority Queue
4. **Week 5-6**: N+1 ìµœì í™” + Event-Driven ì „í™˜
5. **Week 7**: ì„±ëŠ¥ ì¸¡ì • ë° ë¬¸ì„œí™”

---

## ğŸ”— ì°¸ê³  ìë£Œ

- **Redis Write-Behind**: https://redis.io/docs/manual/patterns/
- **CQRS Pattern**: https://martinfowler.com/bliki/CQRS.html
- **LangChain Memory**: https://python.langchain.com/docs/modules/memory/
- **Circuit Breaker**: https://pypi.org/project/circuitbreaker/
- **Django Query Optimization**: https://docs.djangoproject.com/en/4.2/topics/db/optimization/

---

**ë¬¸ì„œ ì‘ì„±ì¼**: 2025-11-21
**í”„ë¡œì íŠ¸**: Resee (ê°„ê²© ë°˜ë³µ í•™ìŠµ í”Œë«í¼)
