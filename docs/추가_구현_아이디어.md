# ì¶”ê°€ êµ¬í˜„ ì•„ì´ë””ì–´ - 2025ë…„ ë°±ì—”ë“œ ì‹ ì… ì·¨ì—… ê°•í™”

> **ì‘ì„±ì¼**: 2025-10-21
> **ëª©ì **: í¬íŠ¸í´ë¦¬ì˜¤ ì°¨ë³„í™”ë¥¼ ìœ„í•œ ì¶”ê°€ êµ¬í˜„ í›„ë³´

---

## ğŸ”¥ 2025ë…„ ë°±ì—”ë“œ ì‹ ì… ì·¨ì—… ìµœê°• ì£¼ì œ TOP 5

### 1ìœ„: **Redis ìºì‹± ì „ëµ (Cache-aside Pattern)** â­â­â­â­â­

**ì¶”ì²œ ì´ìœ **: ì¦‰ì‹œ êµ¬í˜„ ê°€ëŠ¥ + ê·¹ì ì¸ ì„±ê³¼ + ë©´ì ‘ ë‹¨ê³¨ ì§ˆë¬¸

#### êµ¬í˜„ ë‚´ìš©

**ìºì‹± ëŒ€ìƒ API**:
```python
1. GET /api/review/today/ (ì˜¤ëŠ˜ì˜ ë³µìŠµ ëª©ë¡)
   - Before: 200ms (DB ì¡°íšŒ)
   - After: 10ms (Redis ìºì‹±, TTL: 1ì‹œê°„)
   - ì„±ê³¼: 95% ë‹¨ì¶•

2. GET /api/analytics/stats/ (í•™ìŠµ í†µê³„)
   - Before: 500ms (ë³µì¡í•œ ì§‘ê³„ ì¿¼ë¦¬)
   - After: 20ms (Redis ìºì‹±, TTL: 5ë¶„)
   - ì„±ê³¼: 96% ë‹¨ì¶•

3. GET /api/content/?page=1 (ì½˜í…ì¸  ëª©ë¡)
   - Before: 150ms
   - After: 15ms (í˜ì´ì§€ë³„ ìºì‹±, TTL: 10ë¶„)
   - ì„±ê³¼: 90% ë‹¨ì¶•
```

**êµ¬í˜„ ì½”ë“œ ì˜ˆì‹œ**:
```python
# review/views.py
from django.core.cache import cache

class TodayReviewListView(APIView):
    def get(self, request):
        cache_key = f'review:today:{request.user.id}'

        # ìºì‹œ í™•ì¸
        cached_data = cache.get(cache_key)
        if cached_data:
            return Response(cached_data)

        # DB ì¡°íšŒ
        reviews = ReviewSchedule.objects.filter(
            user=request.user,
            next_review_date__lte=timezone.now().date(),
            is_active=True
        ).select_related('content')

        serializer = ReviewScheduleSerializer(reviews, many=True)

        # ìºì‹œ ì €ì¥ (TTL: 1ì‹œê°„)
        cache.set(cache_key, serializer.data, timeout=3600)

        return Response(serializer.data)
```

**ìºì‹œ ë¬´íš¨í™” ì „ëµ**:
```python
# review/views.py
class CompleteReviewView(APIView):
    def post(self, request, schedule_id):
        # ë³µìŠµ ì œì¶œ
        # ...

        # ìºì‹œ ë¬´íš¨í™”
        cache_keys = [
            f'review:today:{request.user.id}',
            f'analytics:stats:{request.user.id}',
        ]
        cache.delete_many(cache_keys)

        return Response(result)
```

#### ì¸¡ì • ê°€ëŠ¥í•œ ì„±ê³¼

- í‰ê·  API ì‘ë‹µ: 250ms â†’ 50ms (**80% ë‹¨ì¶•**)
- DB ë¶€í•˜: 1000 queries/min â†’ 200 queries/min (**80% ê°ì†Œ**)
- Redis hit rate: **85%+**

#### ë©´ì ‘ ê°•ì 

- "ìºì‹± ì „ëµ ì–´ë–»ê²Œ ì„¸ìš°ë‚˜ìš”?"
  * Cache-aside pattern ì„¤ëª…
  * TTL ì„¤ì • ê¸°ì¤€ (ë°ì´í„° ë³€ê²½ ë¹ˆë„)

- "Cache invalidation ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"
  * Write-through: ë°ì´í„° ë³€ê²½ ì‹œ ì¦‰ì‹œ ìºì‹œ ì‚­ì œ
  * ì‚¬ìš©ìë³„ ìºì‹œ í‚¤ ì„¤ê³„

- "Cache stampede ì–´ë–»ê²Œ ë°©ì§€í•˜ë‚˜ìš”?"
  * Lockì„ ì‚¬ìš©í•œ ìºì‹œ ì¬ìƒì„±
  * Probabilistic early expiration

#### êµ¬í˜„ ë‚œì´ë„
â­â­ (ì‰¬ì›€, Redis ì´ë¯¸ ì„¤ì¹˜ë¨)

#### êµ¬í˜„ ì‹œê°„
1-2ì¼

---

### 2ìœ„: **Prometheus + Grafana ëª¨ë‹ˆí„°ë§** â­â­â­â­â­

**ì¶”ì²œ ì´ìœ **: ì°¨ë³„í™” ìµœê°• + ì‹œë‹ˆì–´ë„ ë¶€ì¡±í•œ ì˜ì—­

#### êµ¬í˜„ ë‚´ìš©

**Docker Compose ì„¤ì •**:
```yaml
# docker-compose.yml
prometheus:
  image: prom/prometheus:latest
  ports:
    - "9090:9090"
  volumes:
    - ./prometheus.yml:/etc/prometheus/prometheus.yml
    - prometheus_data:/prometheus
  command:
    - '--config.file=/etc/prometheus/prometheus.yml'

grafana:
  image: grafana/grafana:latest
  ports:
    - "3001:3000"
  volumes:
    - grafana_data:/var/lib/grafana
  environment:
    - GF_SECURITY_ADMIN_PASSWORD=admin
  depends_on:
    - prometheus
```

**Prometheus ì„¤ì •**:
```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'django'
    static_configs:
      - targets: ['backend:8000']

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres_exporter:9187']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis_exporter:9121']
```

**Django ë©”íŠ¸ë¦­ ìˆ˜ì§‘**:
```python
# requirements.txt
django-prometheus==2.3.1

# settings.py
INSTALLED_APPS = [
    'django_prometheus',
    # ...
]

MIDDLEWARE = [
    'django_prometheus.middleware.PrometheusBeforeMiddleware',
    # ...
    'django_prometheus.middleware.PrometheusAfterMiddleware',
]

# urls.py
urlpatterns += [
    path('metrics/', include('django_prometheus.urls')),
]
```

#### ì¸¡ì • ê°€ëŠ¥í•œ ì„±ê³¼

- ì¥ì•  ê°ì§€ ì‹œê°„: 30ë¶„ â†’ 1ë¶„ (**97% ë‹¨ì¶•**)
- ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ:
  * API ì‘ë‹µ ì‹œê°„ (P50, P95, P99)
  * CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
  * DB ì—°ê²° í’€ ì‚¬ìš©ëŸ‰
  * Redis hit/miss rate
  * Celery task ì‹¤í–‰ ì‹œê°„
- Alert ìë™ ë°œì†¡: Slack ì—°ë™

#### Grafana ëŒ€ì‹œë³´ë“œ êµ¬ì„±

1. **API Performance**
   - ìš”ì²­ ìˆ˜ (RPS)
   - ì‘ë‹µ ì‹œê°„ ë¶„í¬
   - ì—ëŸ¬ìœ¨

2. **Infrastructure**
   - CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
   - Disk I/O
   - Network throughput

3. **Database**
   - ì—°ê²° í’€ ì‚¬ìš©ëŸ‰
   - Slow query count
   - Transaction rate

4. **Redis**
   - Hit/Miss rate
   - Memory usage
   - Eviction count

#### ë©´ì ‘ ê°•ì 

- "í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"
  * Prometheus + Grafana ìŠ¤íƒ ì„¤ëª…
  * ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë°©ë²•

- "ì¥ì•  ì–´ë–»ê²Œ ê°ì§€í•˜ë‚˜ìš”?"
  * Alert ê·œì¹™ ì„¤ì •
  * Slack ì•Œë¦¼ ì—°ë™

- "ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"
  * django-prometheus ë¯¸ë“¤ì›¨ì–´
  * Exporter íŒ¨í„´

#### êµ¬í˜„ ë‚œì´ë„
â­â­â­â­ (ë³µì¡, í•˜ì§€ë§Œ ê°•ë ¥)

#### êµ¬í˜„ ì‹œê°„
1ì£¼ì¼

---

### 3ìœ„: **Database Connection Pool ìµœì í™”** â­â­â­â­

**ì¶”ì²œ ì´ìœ **: ì‹¤ë¬´ í•„ìˆ˜ ì§€ì‹ + ì‰½ê²Œ êµ¬í˜„ ê°€ëŠ¥

#### êµ¬í˜„ ë‚´ìš©

**Django ì„¤ì •**:
```python
# settings/base.py
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'resee_prod',
        'USER': 'postgres',
        'PASSWORD': 'password',
        'HOST': 'postgres',
        'PORT': 5432,

        # Connection Pool ì„¤ì •
        'CONN_MAX_AGE': 600,  # ì—°ê²° ì¬ì‚¬ìš© (10ë¶„)
        'CONN_HEALTH_CHECKS': True,  # ì—°ê²° ìƒíƒœ ì²´í¬

        'OPTIONS': {
            'connect_timeout': 10,  # ì—°ê²° íƒ€ì„ì•„ì›ƒ 10ì´ˆ
            'options': '-c statement_timeout=30000',  # SQL íƒ€ì„ì•„ì›ƒ 30ì´ˆ
        },
    }
}
```

**PostgreSQL ì„¤ì •**:
```sql
-- postgresql.conf
max_connections = 100
shared_buffers = 256MB
effective_cache_size = 1GB
work_mem = 4MB
maintenance_work_mem = 64MB
```

**Connection Pool ê³„ì‚° ê³µì‹**:
```
max_connections = (gunicorn_workers Ã— threads_per_worker) + celery_workers + ì—¬ìœ (20%)

ì˜ˆì‹œ (Resee):
= (2 Ã— 2) + 1 + 2
= 7ê°œ í•„ìš”
â†’ PostgreSQL max_connections: 100 (ì¶©ë¶„)
```

#### íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ìŠ¤í† ë¦¬

**ë¬¸ì œ ìƒí™©**:
```
FATAL: remaining connection slots are reserved for non-replication superuser connections
```

**ì›ì¸ ë¶„ì„**:
- Gunicorn workers: 2ê°œ
- Threads per worker: 2ê°œ
- Celery workers: 1ê°œ
- ì´ í•„ìš” ì—°ê²°: 5ê°œ
- PostgreSQL max_connections: ê¸°ë³¸ê°’ 100ê°œ
- â†’ ë¬¸ì œ ì—†ì–´ì•¼ í•˜ëŠ”ë° ì™œ?

**ì‹¤ì œ ì›ì¸**:
- `CONN_MAX_AGE=0` (ì—°ê²° ì¬ì‚¬ìš© ì•ˆ í•¨)
- ë§¤ ìš”ì²­ë§ˆë‹¤ ìƒˆ ì—°ê²° ìƒì„±/ì¢…ë£Œ
- ë™ì‹œ ìš”ì²­ ë§ì„ ë•Œ ì—°ê²° ë¶€ì¡±

**í•´ê²° ë°©ë²•**:
```python
CONN_MAX_AGE = 600  # 10ë¶„ ì¬ì‚¬ìš©
```

#### ì¸¡ì • ê°€ëŠ¥í•œ ì„±ê³¼

- Connection timeout: ë°œìƒ ë¹ˆë„ **100% â†’ 0%**
- ë™ì‹œ ì ‘ì† ì²˜ë¦¬: 50ëª… â†’ 100ëª… (**2ë°°**)
- Connection ìƒì„± ì˜¤ë²„í—¤ë“œ: 10ms â†’ 0ms (ì¬ì‚¬ìš©)
- DB ë¶€í•˜: ì—°ê²° ìƒì„±/ì¢…ë£Œ ë¶€í•˜ **ì œê±°**

#### ë©´ì ‘ ê°•ì 

- "Connection pool ì–´ë–»ê²Œ ì„¤ì •í•˜ë‚˜ìš”?"
  * `CONN_MAX_AGE` ì„¤ì •
  * ê³„ì‚° ê³µì‹

- "max_connections ê³„ì‚° ê³µì‹ì€?"
  * workers Ã— threads + celery + ì—¬ìœ 

- "Connection timeout ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ë‚˜ìš”?"
  * `connect_timeout` ì„¤ì •
  * Health check í™œì„±í™”

#### êµ¬í˜„ ë‚œì´ë„
â­â­ (ì‰¬ì›€, ì„¤ì •ë§Œ ë³€ê²½)

#### êµ¬í˜„ ì‹œê°„
ë°˜ë‚˜ì ˆ (ë¬¸ì„œí™” í¬í•¨)

---

### 4ìœ„: **APM (django-silk or Sentry)** â­â­â­â­

**ì¶”ì²œ ì´ìœ **: ì„±ëŠ¥ ë³‘ëª© ì‹œê°í™” + ì‹¤ë¬´ í•„ìˆ˜

#### êµ¬í˜„ ë‚´ìš© (django-silk)

**ì„¤ì¹˜**:
```bash
pip install django-silk==5.0.4
```

**ì„¤ì •**:
```python
# settings.py
INSTALLED_APPS = [
    'silk',
    # ...
]

MIDDLEWARE = [
    'silk.middleware.SilkyMiddleware',  # ìµœìƒë‹¨
    # ...
]

# Silk ì„¤ì •
SILKY_PYTHON_PROFILER = True
SILKY_PYTHON_PROFILER_BINARY = True
SILKY_MAX_REQUEST_BODY_SIZE = 1024  # 1KB
SILKY_MAX_RESPONSE_BODY_SIZE = 1024

# urls.py
urlpatterns += [
    path('silk/', include('silk.urls', namespace='silk'))
]
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from silk.profiling.profiler import silk_profile

@silk_profile(name='Calculate Review Stats')
def calculate_review_stats(user):
    # ë³µì¡í•œ í†µê³„ ê³„ì‚°
    return stats
```

#### ì¸¡ì • ê°€ëŠ¥í•œ ì„±ê³¼

- Slow query ìë™ ê°ì§€: 100ms ì´ìƒ ì¿¼ë¦¬ ìë™ ê¸°ë¡
- API ì‘ë‹µ ì‹œê°„ ë¶„ì„: ì–´ëŠ APIê°€ ëŠë¦°ì§€ í•œëˆˆì— íŒŒì•…
- SQL ì¿¼ë¦¬ í”„ë¡œíŒŒì¼ë§: N+1 ìë™ ê°ì§€
- Python ì½”ë“œ í”„ë¡œíŒŒì¼ë§: í•¨ìˆ˜ë³„ ì‹¤í–‰ ì‹œê°„

#### Silk ëŒ€ì‹œë³´ë“œ ê¸°ëŠ¥

1. **Requests**: ëª¨ë“  API ìš”ì²­ ëª©ë¡
   - URL, Method, ì‘ë‹µ ì‹œê°„
   - Query count, Time spent in DB

2. **SQL Queries**: ì‹¤í–‰ëœ ëª¨ë“  SQL
   - Query text
   - Execution time
   - Stack trace

3. **Profiling**: Python í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„
   - í•¨ìˆ˜ë³„ ì‹¤í–‰ ì‹œê°„
   - Call stack

4. **Summary**: ì „ì²´ í†µê³„
   - ê°€ì¥ ëŠë¦° API TOP 10
   - ê°€ì¥ ë§ì´ ì‹¤í–‰ëœ Query TOP 10

#### ë©´ì ‘ ê°•ì 

- "ì„±ëŠ¥ ë³‘ëª© ì–´ë–»ê²Œ ì°¾ë‚˜ìš”?"
  * django-silkë¡œ í”„ë¡œíŒŒì¼ë§
  * Slow query ìë™ ê°ì§€

- "N+1 ì¿¼ë¦¬ ì–´ë–»ê²Œ ë°œê²¬í–ˆë‚˜ìš”?"
  * Silkì—ì„œ Query count í™•ì¸
  * ë™ì¼ ì¿¼ë¦¬ ë°˜ë³µ íŒ¨í„´ ê°ì§€

#### êµ¬í˜„ ë‚œì´ë„
â­â­â­ (ì¤‘ê°„)

#### êµ¬í˜„ ì‹œê°„
1-2ì¼

---

### 5ìœ„: **Database Read Replica (Master-Slave)** â­â­â­â­â­

**ì¶”ì²œ ì´ìœ **: ì‹œë‹ˆì–´ ìˆ˜ì¤€ + Scale-out ê²½í—˜

#### êµ¬í˜„ ë‚´ìš©

**Django Database Router**:
```python
# settings.py
DATABASES = {
    'default': {  # Master (Write)
        'ENGINE': 'django.db.backends.postgresql',
        'HOST': 'db-master.reseeall.com',
        'NAME': 'resee_prod',
    },
    'replica': {  # Slave (Read)
        'ENGINE': 'django.db.backends.postgresql',
        'HOST': 'db-replica.reseeall.com',
        'NAME': 'resee_prod',
    }
}

DATABASE_ROUTERS = ['routers.ReplicaRouter']
```

**Database Router êµ¬í˜„**:
```python
# routers.py
class ReplicaRouter:
    def db_for_read(self, model, **hints):
        """ì½ê¸°ëŠ” Replicaë¡œ"""
        return 'replica'

    def db_for_write(self, model, **hints):
        """ì“°ê¸°ëŠ” Masterë¡œ"""
        return 'default'

    def allow_relation(self, obj1, obj2, **hints):
        """Master-Replica ê°„ ê´€ê³„ í—ˆìš©"""
        return True

    def allow_migrate(self, db, app_label, model_name=None, **hints):
        """Migrationì€ Masterë§Œ"""
        return db == 'default'
```

**Replication Lag ì²˜ë¦¬**:
```python
# ì“°ê¸° ì§í›„ ì½ê¸° â†’ Master ì‚¬ìš©
from django.db import transaction

class ContentCreateView(APIView):
    def post(self, request):
        with transaction.atomic():
            content = Content.objects.create(...)

            # ì“°ê¸° ì§í›„ ì½ê¸° â†’ Master ê°•ì œ ì‚¬ìš©
            content_detail = Content.objects.using('default').get(id=content.id)

        return Response(ContentSerializer(content_detail).data)
```

#### AWS RDS ì„¤ì •

**Master ì¸ìŠ¤í„´ìŠ¤**:
- db.t3.small
- Multi-AZ: Yes (HA)

**Read Replica**:
- db.t3.small
- ë™ì¼ Region (ì§€ì—° ìµœì†Œí™”)

**ë¹„ìš©**:
- Master: $30/month
- Replica: $30/month
- ì´: $60/month

#### ì¸¡ì • ê°€ëŠ¥í•œ ì„±ê³¼

- ì½ê¸° ì„±ëŠ¥: **2ë°° í–¥ìƒ** (Master ë¶€í•˜ ë¶„ì‚°)
- Master DB ë¶€í•˜: 100% â†’ 50%
- ë™ì‹œ ì²˜ë¦¬: 100 TPS â†’ 200 TPS
- ì½ê¸° ì¿¼ë¦¬ ì‘ë‹µ ì‹œê°„: 50ms â†’ 25ms

#### íŠ¸ëŸ¬ë¸”ìŠˆíŒ…: Replication Lag

**ë¬¸ì œ**:
- Userê°€ Content ìƒì„± â†’ ë°”ë¡œ ëª©ë¡ ì¡°íšŒ
- Replicaì— ì•„ì§ ë³µì œ ì•ˆ ë¨ â†’ ìƒˆ Content ì•ˆ ë³´ì„

**í•´ê²°**:
```python
# ì“°ê¸° ì§í›„ ì½ê¸°ëŠ” Master ì‚¬ìš©
Content.objects.using('default').filter(author=request.user)
```

#### ë©´ì ‘ ê°•ì 

- "Database Scale-out ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"
  * Master-Slave ë³µì œ êµ¬ì¡°
  * Read Replica í™œìš©

- "Master-Slave ë³µì œ ì§€ì—° ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ë‚˜ìš”?"
  * Replication lag ëª¨ë‹ˆí„°ë§
  * ì“°ê¸° ì§í›„ ì½ê¸°ëŠ” Master ì‚¬ìš©

- "Write í›„ Read ì¼ê´€ì„± ì–´ë–»ê²Œ ë³´ì¥í•˜ë‚˜ìš”?"
  * `using('default')` ëª…ì‹œ
  * Sticky session

#### êµ¬í˜„ ë‚œì´ë„
â­â­â­â­â­ (ë§¤ìš° ë³µì¡, AWS RDS í•„ìš”)

#### êµ¬í˜„ ì‹œê°„
1-2ì£¼ (AWS ì„¤ì • í¬í•¨)

---

## ğŸ¯ êµ¬í˜„ ìš°ì„ ìˆœìœ„ (ì¶”ì²œ)

### **ì¦‰ì‹œ êµ¬í˜„ (1ì£¼ì¼ ì´ë‚´)**:
1. **Redis ìºì‹±** â­â­â­â­â­ **(ê°€ì¥ ì¶”ì²œ!)**
   - ì‹œê°„: 1-2ì¼
   - ì„±ê³¼: API ì‘ë‹µ 80% ë‹¨ì¶•
   - ë‚œì´ë„: ì‰¬ì›€

2. **Connection Pool ìµœì í™”** â­â­â­â­
   - ì‹œê°„: ë°˜ë‚˜ì ˆ
   - ì„±ê³¼: Connection timeout ì œê±°
   - ë‚œì´ë„: ë§¤ìš° ì‰¬ì›€

### **ë„ì „ ê°€ì¹˜ ìˆìŒ (2-3ì£¼)**:
3. **django-silk APM** â­â­â­â­
   - ì‹œê°„: 1-2ì¼
   - ì„±ê³¼: ì„±ëŠ¥ ë³‘ëª© ì‹œê°í™”
   - ë‚œì´ë„: ì¤‘ê°„

4. **Prometheus + Grafana** â­â­â­â­â­
   - ì‹œê°„: 1ì£¼ì¼
   - ì„±ê³¼: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
   - ë‚œì´ë„: ë³µì¡ (í•˜ì§€ë§Œ ì°¨ë³„í™” ìµœê°•!)

### **ì¥ê¸° í”„ë¡œì íŠ¸ (1-2ê°œì›”)**:
5. **Database Read Replica** â­â­â­â­â­
   - ì‹œê°„: 1-2ì£¼
   - ì„±ê³¼: Scale-out ê²½í—˜
   - ë‚œì´ë„: ë§¤ìš° ë³µì¡

---

## ğŸ’¡ ê°œì¸ì  ì¶”ì²œ

**ë‹¨ê¸° (ì´ë²ˆ ì£¼)**:
1. Redis ìºì‹± êµ¬í˜„ (1-2ì¼)
2. Connection Pool ë¬¸ì„œí™” (ë°˜ë‚˜ì ˆ)

**ì¤‘ê¸° (ì´ë²ˆ ë‹¬)**:
3. django-silk ì„¤ì¹˜ + í”„ë¡œíŒŒì¼ë§ (1-2ì¼)
4. Prometheus + Grafana êµ¬ì¶• (1ì£¼ì¼)

**ì¥ê¸° (ì—¬ìœ  ìˆì„ ë•Œ)**:
5. Read Replica êµ¬ì¶• (AWS RDS í•„ìš”)

---

## ğŸš« ì œì™¸ëœ ì•„ì´ë””ì–´

### **LangChainìœ¼ë¡œ ì£¼ê°„ ì‹œí—˜ ì„±ëŠ¥ í–¥ìƒ**
**ì œì™¸ ì´ìœ **:
- âŒ ì¸¡ì • ê°€ëŠ¥í•œ ì„±ê³¼ ë¶ˆëª…í™• ("ì„±ëŠ¥ í–¥ìƒ"ì´ ëª¨í˜¸)
- âŒ ì´ë¯¸ Anthropic SDK ì§ì ‘ ì‚¬ìš© ì¤‘ (claude-3-haiku)
- âŒ LangChain ì¶”ê°€ = ë¶ˆí•„ìš”í•œ ë³µì¡ë„ ì¦ê°€
- âŒ ë©´ì ‘ì—ì„œ "ì™œ LangChain?" ì§ˆë¬¸ì— ë‹µë³€ ì–´ë ¤ì›€

**í˜„ì¬ ë°©ì‹ì´ ë” ë‚˜ì€ ì´ìœ **:
```python
# í˜„ì¬: Anthropic SDK ì§ì ‘ ì‚¬ìš©
from anthropic import Anthropic
client = Anthropic(api_key=settings.ANTHROPIC_API_KEY)
response = client.messages.create(...)

# LangChain ì‚¬ìš© ì‹œ
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
# ... ë¶ˆí•„ìš”í•œ boilerplate ì½”ë“œ ì¦ê°€
```

**LangChainì´ ìœ ìš©í•œ ê²½ìš°**:
- RAG (Retrieval-Augmented Generation) êµ¬í˜„
- ë³µì¡í•œ Chain êµ¬ì„± (Multi-step reasoning)
- Agent ì‹œìŠ¤í…œ (Tool calling)

**ReseeëŠ” ë‹¨ìˆœ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©** â†’ LangChain ë¶ˆí•„ìš”

---

**ì‘ì„±ì¼**: 2025-10-21
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-10-21
