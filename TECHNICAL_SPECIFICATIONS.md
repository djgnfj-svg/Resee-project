# ğŸ”§ Resee ê¸°ìˆ  ëª…ì„¸ì„œ

> **ì‘ì„±ì¼**: 2025-01-21  
> **ë²„ì „**: v1.0  
> **ëŒ€ìƒ**: ê°œë°œíŒ€, PM

---

## ğŸ“‹ ë¬¸ì„œ ê°œìš”

ì´ ë¬¸ì„œëŠ” Resee í”„ë¡œì íŠ¸ì˜ ì¶”ê°€ ê°œë°œì´ í•„ìš”í•œ ê¸°ëŠ¥ë“¤ì— ëŒ€í•œ ìƒì„¸ ê¸°ìˆ  ëª…ì„¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

---

## ğŸ–¥ï¸ 1. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ í”„ë¡ íŠ¸ì—”ë“œ

### 1.1 ê¸°ìˆ  ìŠ¤íƒ
```typescript
// Frontend Stack
- React 18.2.0
- TypeScript 4.9.3
- TailwindCSS 3.2.4
- Recharts 2.15.4 (ì°¨íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬)
- TanStack Query 4.16.1 (ì„œë²„ ìƒíƒœ ê´€ë¦¬)
- React Hook Form 7.39.4 (í¼ ê´€ë¦¬)
```

### 1.2 ì•„í‚¤í…ì²˜ ì„¤ê³„
```
frontend/src/
â”œâ”€â”€ pages/
â”‚   â””â”€â”€ admin/
â”‚       â”œâ”€â”€ MonitoringDashboard.tsx      # ë©”ì¸ ëŒ€ì‹œë³´ë“œ í˜ì´ì§€
â”‚       â”œâ”€â”€ SystemHealth.tsx             # ì‹œìŠ¤í…œ ìƒíƒœ í˜ì´ì§€
â”‚       â”œâ”€â”€ APIMetrics.tsx               # API ì„±ëŠ¥ í˜ì´ì§€
â”‚       â”œâ”€â”€ UserAnalytics.tsx            # ì‚¬ìš©ì ë¶„ì„ í˜ì´ì§€
â”‚       â””â”€â”€ ErrorLogs.tsx                # ì—ëŸ¬ ë¡œê·¸ í˜ì´ì§€
â”œâ”€â”€ components/
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ SystemStatusCard.tsx         # ì‹œìŠ¤í…œ ìƒíƒœ ì¹´ë“œ
â”‚       â”œâ”€â”€ PerformanceChart.tsx         # ì„±ëŠ¥ ì°¨íŠ¸
â”‚       â”œâ”€â”€ ErrorLogTable.tsx            # ì—ëŸ¬ ë¡œê·¸ í…Œì´ë¸”
â”‚       â”œâ”€â”€ UserActivityChart.tsx        # ì‚¬ìš©ì í™œë™ ì°¨íŠ¸
â”‚       â”œâ”€â”€ AIUsageChart.tsx             # AI ì‚¬ìš©ëŸ‰ ì°¨íŠ¸
â”‚       â””â”€â”€ AlertPanel.tsx               # ì•Œë¦¼ íŒ¨ë„
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ useSystemHealth.ts           # ì‹œìŠ¤í…œ ìƒíƒœ í›…
â”‚       â”œâ”€â”€ useAPIMetrics.ts             # API ë©”íŠ¸ë¦­ í›…
â”‚       â”œâ”€â”€ useErrorLogs.ts              # ì—ëŸ¬ ë¡œê·¸ í›…
â”‚       â””â”€â”€ useUserActivity.ts           # ì‚¬ìš©ì í™œë™ í›…
â””â”€â”€ types/
    â””â”€â”€ monitoring.ts                    # ëª¨ë‹ˆí„°ë§ íƒ€ì… ì •ì˜
```

### 1.3 API ì—°ë™ ëª…ì„¸
```typescript
// ê¸°ì¡´ ë°±ì—”ë“œ API ì—”ë“œí¬ì¸íŠ¸ í™œìš©
interface MonitoringAPIs {
  // ì‹œìŠ¤í…œ ìƒíƒœ
  '/api/monitoring/dashboard/': {
    method: 'GET';
    response: DashboardOverview;
    auth: 'admin';
  };
  
  // API ì„±ëŠ¥ ë©”íŠ¸ë¦­
  '/api/monitoring/api-metrics/': {
    method: 'GET';
    params: { timeframe: '24h' | '7d' | '30d' };
    response: APIMetrics[];
    auth: 'admin';
  };
  
  // ì—ëŸ¬ ë¡œê·¸
  '/api/monitoring/error-logs/': {
    method: 'GET';
    params: { level: 'ERROR' | 'CRITICAL'; limit: number };
    response: ErrorLog[];
    auth: 'admin';
  };
  
  // ì‚¬ìš©ì í™œë™
  '/api/monitoring/user-activity/': {
    method: 'GET';
    params: { period: 'today' | 'week' | 'month' };
    response: UserActivity[];
    auth: 'admin';
  };
}
```

### 1.4 UI ì»´í¬ë„ŒíŠ¸ ëª…ì„¸
```typescript
// ì‹œìŠ¤í…œ ìƒíƒœ ì¹´ë“œ
interface SystemStatusCardProps {
  title: string;
  value: number | string;
  unit?: string;
  status: 'healthy' | 'warning' | 'critical';
  trend?: 'up' | 'down' | 'stable';
  onClick?: () => void;
}

// ì„±ëŠ¥ ì°¨íŠ¸
interface PerformanceChartProps {
  data: MetricDataPoint[];
  type: 'line' | 'area' | 'bar';
  height?: number;
  showLegend?: boolean;
  timeRange: '1h' | '24h' | '7d' | '30d';
}

// ì—ëŸ¬ ë¡œê·¸ í…Œì´ë¸”
interface ErrorLogTableProps {
  logs: ErrorLog[];
  onResolve: (id: string) => void;
  onViewDetails: (log: ErrorLog) => void;
  pagination: PaginationProps;
}
```

### 1.5 ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
```typescript
// WebSocket ë˜ëŠ” í´ë§ì„ í†µí•œ ì‹¤ì‹œê°„ ë°ì´í„°
const useRealTimeMonitoring = () => {
  const queryClient = useQueryClient();
  
  useEffect(() => {
    const interval = setInterval(() => {
      // 5ì´ˆë§ˆë‹¤ ì¤‘ìš” ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
      queryClient.invalidateQueries(['system-health']);
      queryClient.invalidateQueries(['api-metrics']);
    }, 5000);
    
    return () => clearInterval(interval);
  }, [queryClient]);
};
```

---

## ğŸ”” 2. ì•Œë¦¼ ì‹œìŠ¤í…œ

### 2.1 ê¸°ìˆ  ìŠ¤íƒ
```python
# Backend Stack
- Django 4.2 (ê¸°ì¡´)
- Celery (ê¸°ì¡´ - ë¹„ë™ê¸° ì‘ì—…ìš©)
- Redis (ê¸°ì¡´ - ë©”ì‹œì§€ ë¸Œë¡œì»¤)
- python-slack-sdk 3.21.3 (Slack ì—°ë™)
- django-ses (ì´ë©”ì¼ ë°œì†¡)
```

### 2.2 ì•„í‚¤í…ì²˜ ì„¤ê³„
```
backend/
â”œâ”€â”€ alerts/                           # ìƒˆë¡œìš´ Django ì•±
â”‚   â”œâ”€â”€ models.py                     # ì•Œë¦¼ ê·œì¹™, íˆìŠ¤í† ë¦¬ ëª¨ë¸
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ alert_engine.py           # ì•Œë¦¼ ê·œì¹™ ì—”ì§„
â”‚   â”‚   â”œâ”€â”€ slack_notifier.py         # Slack ì•Œë¦¼ ì„œë¹„ìŠ¤
â”‚   â”‚   â”œâ”€â”€ email_notifier.py         # ì´ë©”ì¼ ì•Œë¦¼ ì„œë¹„ìŠ¤
â”‚   â”‚   â””â”€â”€ notification_manager.py   # ì•Œë¦¼ ê´€ë¦¬ì
â”‚   â”œâ”€â”€ tasks.py                      # Celery ë¹„ë™ê¸° ì‘ì—…
â”‚   â”œâ”€â”€ serializers.py                # API ì‹œë¦¬ì–¼ë¼ì´ì €
â”‚   â””â”€â”€ views.py                      # ì•Œë¦¼ ì„¤ì • API
â”œâ”€â”€ monitoring/
â”‚   â””â”€â”€ signals.py                    # ëª¨ë‹ˆí„°ë§ ë°ì´í„° ê¸°ë°˜ ì•Œë¦¼ íŠ¸ë¦¬ê±°
```

### 2.3 ì•Œë¦¼ ê·œì¹™ ì •ì˜
```python
# ì•Œë¦¼ ëª¨ë¸
class AlertRule(models.Model):
    ALERT_TYPES = [
        ('system_error', 'System Error'),
        ('performance', 'Performance Issue'),
        ('security', 'Security Alert'),
        ('business', 'Business Metric Alert'),
    ]
    
    SEVERITY_LEVELS = [
        ('low', 'Low'),
        ('medium', 'Medium'), 
        ('high', 'High'),
        ('critical', 'Critical'),
    ]
    
    name = models.CharField(max_length=100)
    alert_type = models.CharField(max_length=20, choices=ALERT_TYPES)
    severity = models.CharField(max_length=10, choices=SEVERITY_LEVELS)
    
    # ì¡°ê±´ ì„¤ì •
    metric_name = models.CharField(max_length=50)  # 'cpu_usage', 'error_count', etc.
    condition = models.CharField(max_length=10)    # '>', '<', '==', '!='
    threshold_value = models.FloatField()
    time_window_minutes = models.IntegerField(default=5)
    
    # ì•Œë¦¼ ì„¤ì •
    slack_enabled = models.BooleanField(default=True)
    email_enabled = models.BooleanField(default=True)
    slack_channel = models.CharField(max_length=50, default='#alerts')
    email_recipients = models.JSONField(default=list)
    
    # ì¤‘ë³µ ë°©ì§€
    cooldown_minutes = models.IntegerField(default=30)
    max_alerts_per_hour = models.IntegerField(default=10)
    
    is_active = models.BooleanField(default=True)
    created_at = models.DateTimeField(auto_now_add=True)

# ì•Œë¦¼ íˆìŠ¤í† ë¦¬
class AlertHistory(models.Model):
    rule = models.ForeignKey(AlertRule, on_delete=models.CASCADE)
    triggered_at = models.DateTimeField(auto_now_add=True)
    metric_value = models.FloatField()
    message = models.TextField()
    
    # ë°œì†¡ ìƒíƒœ
    slack_sent = models.BooleanField(default=False)
    email_sent = models.BooleanField(default=False)
    slack_response = models.JSONField(null=True, blank=True)
    email_response = models.JSONField(null=True, blank=True)
    
    resolved_at = models.DateTimeField(null=True, blank=True)
    resolved_by = models.ForeignKey(User, on_delete=models.SET_NULL, null=True)
```

### 2.4 ì•Œë¦¼ ì—”ì§„ êµ¬í˜„
```python
# alerts/services/alert_engine.py
class AlertEngine:
    def __init__(self):
        self.slack_notifier = SlackNotifier()
        self.email_notifier = EmailNotifier()
    
    def check_alert_conditions(self):
        """ëª¨ë“  í™œì„± ì•Œë¦¼ ê·œì¹™ì„ í™•ì¸í•˜ê³  ì¡°ê±´ì— ë§ìœ¼ë©´ ì•Œë¦¼ ë°œì†¡"""
        active_rules = AlertRule.objects.filter(is_active=True)
        
        for rule in active_rules:
            if self._should_check_rule(rule):
                metric_value = self._get_metric_value(rule)
                
                if self._condition_met(rule, metric_value):
                    if not self._in_cooldown(rule):
                        self._send_alert(rule, metric_value)
    
    def _get_metric_value(self, rule: AlertRule) -> float:
        """í˜„ì¬ ë©”íŠ¸ë¦­ ê°’ì„ ê°€ì ¸ì˜´"""
        now = timezone.now()
        time_window = now - timedelta(minutes=rule.time_window_minutes)
        
        if rule.metric_name == 'cpu_usage':
            return SystemHealth.objects.filter(
                timestamp__gte=time_window
            ).aggregate(avg_cpu=Avg('cpu_usage_percent'))['avg_cpu'] or 0
            
        elif rule.metric_name == 'error_count':
            return ErrorLog.objects.filter(
                timestamp__gte=time_window,
                level__in=['ERROR', 'CRITICAL']
            ).count()
            
        elif rule.metric_name == 'api_response_time':
            return APIMetrics.objects.filter(
                timestamp__gte=time_window
            ).aggregate(avg_time=Avg('response_time_ms'))['avg_time'] or 0
        
        # ì¶”ê°€ ë©”íŠ¸ë¦­ë“¤...
        
    def _send_alert(self, rule: AlertRule, metric_value: float):
        """ì•Œë¦¼ ë°œì†¡"""
        message = self._build_message(rule, metric_value)
        
        # ì•Œë¦¼ íˆìŠ¤í† ë¦¬ ìƒì„±
        alert_history = AlertHistory.objects.create(
            rule=rule,
            metric_value=metric_value,
            message=message
        )
        
        # Slack ì•Œë¦¼
        if rule.slack_enabled:
            slack_result = self.slack_notifier.send_alert(
                channel=rule.slack_channel,
                message=message,
                severity=rule.severity
            )
            alert_history.slack_sent = slack_result.get('success', False)
            alert_history.slack_response = slack_result
        
        # ì´ë©”ì¼ ì•Œë¦¼  
        if rule.email_enabled and rule.email_recipients:
            email_result = self.email_notifier.send_alert(
                recipients=rule.email_recipients,
                subject=f"[{rule.severity.upper()}] {rule.name}",
                message=message
            )
            alert_history.email_sent = email_result.get('success', False)
            alert_history.email_response = email_result
            
        alert_history.save()
```

### 2.5 Celery ì‘ì—… ì •ì˜
```python
# alerts/tasks.py
from celery import shared_task
from .services.alert_engine import AlertEngine

@shared_task
def check_system_alerts():
    """ì‹œìŠ¤í…œ ì•Œë¦¼ ê·œì¹™ í™•ì¸ (ë§¤ 1ë¶„ë§ˆë‹¤ ì‹¤í–‰)"""
    engine = AlertEngine()
    engine.check_alert_conditions()

@shared_task  
def send_daily_report():
    """ì¼ì¼ ì‹œìŠ¤í…œ ìƒíƒœ ë¦¬í¬íŠ¸ ë°œì†¡"""
    # ì¼ì¼ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ë° ë°œì†¡
    pass

@shared_task
def cleanup_old_alerts():
    """ì˜¤ë˜ëœ ì•Œë¦¼ íˆìŠ¤í† ë¦¬ ì •ë¦¬ (ë§¤ì¼ ì‹¤í–‰)"""
    cutoff_date = timezone.now() - timedelta(days=30)
    AlertHistory.objects.filter(triggered_at__lt=cutoff_date).delete()

# Celery Beat ìŠ¤ì¼€ì¤„ (settings.py)
CELERY_BEAT_SCHEDULE = {
    'check-system-alerts': {
        'task': 'alerts.tasks.check_system_alerts',
        'schedule': crontab(minute='*'),  # ë§¤ë¶„ ì‹¤í–‰
    },
    'send-daily-report': {
        'task': 'alerts.tasks.send_daily_report', 
        'schedule': crontab(hour=9, minute=0),  # ë§¤ì¼ ì˜¤ì „ 9ì‹œ
    },
    'cleanup-old-alerts': {
        'task': 'alerts.tasks.cleanup_old_alerts',
        'schedule': crontab(hour=2, minute=0),  # ë§¤ì¼ ì˜¤ì „ 2ì‹œ
    },
}
```

---

## âš¡ 3. ì„±ëŠ¥ ìµœì í™”

### 3.1 ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
```sql
-- ì¶”ê°€í•  ì¸ë±ìŠ¤ë“¤
-- ë³µìŠµ ì‹œìŠ¤í…œ ìµœì í™”
CREATE INDEX CONCURRENTLY idx_review_schedule_user_date 
ON review_reviewschedule(user_id, next_review_date) 
WHERE next_review_date <= CURRENT_DATE;

-- API ë©”íŠ¸ë¦­ ìµœì í™”
CREATE INDEX CONCURRENTLY idx_api_metrics_endpoint_date_time
ON monitoring_api_metrics(endpoint, date, response_time_ms);

-- AI ë©”íŠ¸ë¦­ ìµœì í™”  
CREATE INDEX CONCURRENTLY idx_ai_metrics_user_date_cost
ON monitoring_ai_metrics(user_id, date, cost_usd);

-- ì‚¬ìš©ì í™œë™ ìµœì í™”
CREATE INDEX CONCURRENTLY idx_user_activity_compound
ON monitoring_user_activity(date, api_requests_count, reviews_completed_count);
```

```python
# ORM ì¿¼ë¦¬ ìµœì í™” ì˜ˆì‹œ
# Before (N+1 ë¬¸ì œ)
def get_user_reviews_slow():
    schedules = ReviewSchedule.objects.filter(
        next_review_date__lte=timezone.now().date()
    )
    for schedule in schedules:
        content_title = schedule.content.title  # N+1 ì¿¼ë¦¬ ë°œìƒ
        user_email = schedule.user.email        # N+1 ì¿¼ë¦¬ ë°œìƒ

# After (ìµœì í™”ëœ ì¿¼ë¦¬)
def get_user_reviews_optimized():
    schedules = ReviewSchedule.objects.filter(
        next_review_date__lte=timezone.now().date()
    ).select_related('content', 'user')  # JOINìœ¼ë¡œ í•œ ë²ˆì— ê°€ì ¸ì˜´
    
    for schedule in schedules:
        content_title = schedule.content.title  # ì¶”ê°€ ì¿¼ë¦¬ ì—†ìŒ
        user_email = schedule.user.email        # ì¶”ê°€ ì¿¼ë¦¬ ì—†ìŒ
```

### 3.2 ìºì‹± ì „ëµ
```python
# Redis ìºì‹œ ì„¤ì • ê°•í™”
CACHES = {
    'default': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': 'redis://redis:6379/1',
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.DefaultClient',
            'SERIALIZER': 'django_redis.serializers.json.JSONSerializer',
        },
        'KEY_PREFIX': 'resee',
        'VERSION': 1,
    },
    # ì„¸ì…˜ë³„ ìºì‹œ ë¶„ë¦¬
    'sessions': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': 'redis://redis:6379/2',
        'TIMEOUT': 86400,  # 24ì‹œê°„
    },
    # API ì‘ë‹µ ìºì‹œ
    'api_responses': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': 'redis://redis:6379/3', 
        'TIMEOUT': 300,    # 5ë¶„
    }
}

# ìºì‹œ ë°ì½”ë ˆì´í„° í™œìš©
from django.views.decorators.cache import cache_page
from django.core.cache import cache

@cache_page(60 * 5, cache='api_responses')  # 5ë¶„ ìºì‹±
def api_statistics_view(request):
    # í†µê³„ ë°ì´í„° API
    pass

# ë³µì¡í•œ ì¿¼ë¦¬ ê²°ê³¼ ìºì‹±
def get_user_learning_stats(user_id, cache_timeout=300):
    cache_key = f'learning_stats_{user_id}'
    stats = cache.get(cache_key)
    
    if stats is None:
        stats = {
            'total_reviews': ReviewHistory.objects.filter(user_id=user_id).count(),
            'success_rate': ReviewHistory.objects.filter(
                user_id=user_id, result='remembered'
            ).count() / max(1, ReviewHistory.objects.filter(user_id=user_id).count()),
            # ê¸°íƒ€ í†µê³„ ê³„ì‚°...
        }
        cache.set(cache_key, stats, cache_timeout)
    
    return stats
```

---

## ğŸ“Š 4. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤ ëŒ€ì‹œë³´ë“œ

### 4.1 ë°ì´í„° ëª¨ë¸ í™•ì¥
```python
# analytics/models.py
class LearningPattern(models.Model):
    """ì‚¬ìš©ì í•™ìŠµ íŒ¨í„´ ë¶„ì„"""
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    date = models.DateField()
    
    # í•™ìŠµ ì‹œê°„ íŒ¨í„´
    morning_activity_score = models.FloatField(default=0)    # 0-100
    afternoon_activity_score = models.FloatField(default=0)
    evening_activity_score = models.FloatField(default=0)
    
    # ë³µìŠµ íŒ¨í„´
    avg_review_interval_days = models.FloatField(default=0)
    preferred_review_count_per_session = models.IntegerField(default=0)
    success_rate_trend = models.FloatField(default=0)       # -1 to 1
    
    # ì½˜í…ì¸  ì„ í˜¸ë„
    preferred_content_length = models.CharField(max_length=20, default='medium')  # short/medium/long
    most_active_category = models.CharField(max_length=100, blank=True)
    
    # AI ì‚¬ìš© íŒ¨í„´
    ai_dependency_score = models.FloatField(default=0)      # 0-100
    question_type_preference = models.JSONField(default=dict)
    
    class Meta:
        unique_together = ['user', 'date']

class ConversionFunnel(models.Model):
    """êµ¬ë… ì „í™˜ í¼ë„ ë¶„ì„"""
    date = models.DateField()
    
    # í¼ë„ ë‹¨ê³„ë³„ ì‚¬ìš©ì ìˆ˜
    visitors = models.IntegerField(default=0)
    signups = models.IntegerField(default=0)
    email_verified = models.IntegerField(default=0)
    first_content_created = models.IntegerField(default=0)
    first_review_completed = models.IntegerField(default=0)
    upgraded_to_basic = models.IntegerField(default=0)
    upgraded_to_pro = models.IntegerField(default=0)
    
    # ì „í™˜ìœ¨ (ìë™ ê³„ì‚°)
    signup_rate = models.FloatField(default=0)
    verification_rate = models.FloatField(default=0)
    activation_rate = models.FloatField(default=0)
    basic_conversion_rate = models.FloatField(default=0)
    pro_conversion_rate = models.FloatField(default=0)
    
    class Meta:
        unique_together = ['date']
```

### 4.2 ë¶„ì„ ì„œë¹„ìŠ¤
```python
# analytics/services/bi_analyzer.py
class BIAnalyzer:
    def generate_learning_insights(self, user_id: int, days: int = 30):
        """ì‚¬ìš©ìë³„ í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        end_date = timezone.now().date()
        start_date = end_date - timedelta(days=days)
        
        # ë³µìŠµ ì„±ê³µë¥  íŠ¸ë Œë“œ
        success_trend = self._calculate_success_trend(user_id, start_date, end_date)
        
        # ìµœì  í•™ìŠµ ì‹œê°„ëŒ€ ë¶„ì„
        optimal_time = self._find_optimal_learning_time(user_id, start_date, end_date)
        
        # ì½˜í…ì¸  ì¶”ì²œ
        content_recommendations = self._generate_content_recommendations(user_id)
        
        return {
            'success_trend': success_trend,
            'optimal_learning_time': optimal_time,
            'recommendations': content_recommendations,
            'insights': self._generate_textual_insights(user_id, days)
        }
    
    def analyze_cohort_retention(self, cohort_month: str):
        """ì½”í˜¸íŠ¸ ë¶„ì„ - ì›”ë³„ ì‚¬ìš©ì ë¦¬í…ì…˜"""
        cohort_users = User.objects.filter(
            date_joined__year=int(cohort_month.split('-')[0]),
            date_joined__month=int(cohort_month.split('-')[1])
        )
        
        retention_data = {}
        for weeks in range(1, 13):  # 12ì£¼ê°„ ì¶”ì 
            week_start = timezone.now().date() - timedelta(weeks=weeks)
            week_end = week_start + timedelta(days=7)
            
            active_users = UserActivity.objects.filter(
                user__in=cohort_users,
                date__range=[week_start, week_end]
            ).values('user').distinct().count()
            
            retention_rate = active_users / cohort_users.count() * 100
            retention_data[f'week_{weeks}'] = retention_rate
            
        return retention_data
```

---

## ğŸ§ª 5. A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬

### 5.1 ì‹¤í—˜ ê´€ë¦¬ ëª¨ë¸
```python
# experiments/models.py
class Experiment(models.Model):
    EXPERIMENT_STATUS = [
        ('draft', 'Draft'),
        ('running', 'Running'), 
        ('paused', 'Paused'),
        ('completed', 'Completed'),
    ]
    
    name = models.CharField(max_length=100)
    description = models.TextField()
    hypothesis = models.TextField()
    
    # ì‹¤í—˜ ì„¤ì •
    start_date = models.DateTimeField()
    end_date = models.DateTimeField()
    status = models.CharField(max_length=10, choices=EXPERIMENT_STATUS, default='draft')
    
    # ëŒ€ìƒ ì‚¬ìš©ì ì„¤ì •
    target_user_percentage = models.FloatField(default=50.0)  # 0-100%
    user_filter_criteria = models.JSONField(default=dict)     # í•„í„° ì¡°ê±´
    
    # ì„±ê³µ ì§€í‘œ
    primary_metric = models.CharField(max_length=50)
    secondary_metrics = models.JSONField(default=list)
    minimum_sample_size = models.IntegerField(default=1000)
    
    # ì‹¤í—˜ ê²°ê³¼
    statistical_significance = models.FloatField(null=True, blank=True)
    winner_variant = models.CharField(max_length=50, blank=True)
    
    created_by = models.ForeignKey(User, on_delete=models.CASCADE)

class ExperimentVariant(models.Model):
    experiment = models.ForeignKey(Experiment, on_delete=models.CASCADE)
    name = models.CharField(max_length=50)  # 'control', 'variant_a', etc.
    description = models.TextField()
    traffic_percentage = models.FloatField(default=50.0)
    
    # ë³€ê²½ì‚¬í•­ ì •ì˜
    feature_flags = models.JSONField(default=dict)
    config_overrides = models.JSONField(default=dict)

class ExperimentAssignment(models.Model):
    """ì‚¬ìš©ìë³„ ì‹¤í—˜ ë°°ì •"""
    experiment = models.ForeignKey(Experiment, on_delete=models.CASCADE)
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    variant = models.ForeignKey(ExperimentVariant, on_delete=models.CASCADE)
    assigned_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        unique_together = ['experiment', 'user']

class ExperimentEvent(models.Model):
    """ì‹¤í—˜ ì´ë²¤íŠ¸ ì¶”ì """
    assignment = models.ForeignKey(ExperimentAssignment, on_delete=models.CASCADE)
    event_name = models.CharField(max_length=100)  # 'page_view', 'signup', 'purchase', etc.
    event_data = models.JSONField(default=dict)
    timestamp = models.DateTimeField(auto_now_add=True)
```

### 5.2 ì‹¤í—˜ ì—”ì§„
```python
# experiments/services/experiment_engine.py
class ExperimentEngine:
    def assign_user_to_experiment(self, user: User, experiment_name: str):
        """ì‚¬ìš©ìë¥¼ ì‹¤í—˜ì— ë°°ì •"""
        try:
            experiment = Experiment.objects.get(
                name=experiment_name, 
                status='running',
                start_date__lte=timezone.now(),
                end_date__gte=timezone.now()
            )
        except Experiment.DoesNotExist:
            return None
            
        # ì´ë¯¸ ë°°ì •ëœ ì‚¬ìš©ìì¸ì§€ í™•ì¸
        existing_assignment = ExperimentAssignment.objects.filter(
            experiment=experiment,
            user=user
        ).first()
        
        if existing_assignment:
            return existing_assignment.variant
            
        # ì‚¬ìš©ìê°€ ì‹¤í—˜ ëŒ€ìƒì¸ì§€ í™•ì¸
        if not self._is_eligible_user(user, experiment):
            return None
            
        # ë°°ì • ë¡œì§ (í•´ì‹œ ê¸°ë°˜ìœ¼ë¡œ ì¼ê´€ëœ ë°°ì •)
        user_hash = hash(f"{experiment.id}_{user.id}") % 100
        
        cumulative_percentage = 0
        for variant in experiment.experimentvariant_set.all():
            cumulative_percentage += variant.traffic_percentage
            if user_hash < cumulative_percentage:
                # ì‚¬ìš©ì ë°°ì • ìƒì„±
                assignment = ExperimentAssignment.objects.create(
                    experiment=experiment,
                    user=user,
                    variant=variant
                )
                return variant
        
        return None  # ì‹¤í—˜ì— ë°°ì •ë˜ì§€ ì•ŠìŒ
    
    def track_event(self, user: User, event_name: str, event_data: dict = None):
        """ì‹¤í—˜ ê´€ë ¨ ì´ë²¤íŠ¸ ì¶”ì """
        # ì‚¬ìš©ìì˜ í™œì„± ì‹¤í—˜ ë°°ì • ì°¾ê¸°
        active_assignments = ExperimentAssignment.objects.filter(
            user=user,
            experiment__status='running',
            experiment__start_date__lte=timezone.now(),
            experiment__end_date__gte=timezone.now()
        )
        
        for assignment in active_assignments:
            ExperimentEvent.objects.create(
                assignment=assignment,
                event_name=event_name,
                event_data=event_data or {}
            )
    
    def get_experiment_results(self, experiment_id: int):
        """ì‹¤í—˜ ê²°ê³¼ ë¶„ì„"""
        experiment = Experiment.objects.get(id=experiment_id)
        variants = experiment.experimentvariant_set.all()
        
        results = {}
        for variant in variants:
            # ë³€í˜•ë³„ ì‚¬ìš©ì ìˆ˜
            total_users = ExperimentAssignment.objects.filter(
                experiment=experiment,
                variant=variant
            ).count()
            
            # ì£¼ìš” ì§€í‘œë³„ ì „í™˜ìœ¨ ê³„ì‚°
            primary_conversions = ExperimentEvent.objects.filter(
                assignment__experiment=experiment,
                assignment__variant=variant,
                event_name=experiment.primary_metric
            ).values('assignment__user').distinct().count()
            
            conversion_rate = primary_conversions / max(1, total_users) * 100
            
            results[variant.name] = {
                'total_users': total_users,
                'conversions': primary_conversions,
                'conversion_rate': conversion_rate
            }
        
        # í†µê³„ì  ìœ ì˜ì„± ê²€ì •
        significance = self._calculate_statistical_significance(results)
        
        return {
            'results': results,
            'statistical_significance': significance,
            'recommended_winner': self._determine_winner(results, significance)
        }
```

---

## ğŸ”§ 6. êµ¬í˜„ ê°€ì´ë“œë¼ì¸

### 6.1 ì½”ë“œ í’ˆì§ˆ ê¸°ì¤€
```python
# ëª¨ë“  ìƒˆë¡œìš´ ì½”ë“œëŠ” ë‹¤ìŒ ê¸°ì¤€ì„ ì¤€ìˆ˜í•´ì•¼ í•¨:
1. í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ > 80%
2. Type hints 100% ì ìš© (Python)
3. ESLint/TypeScript strict mode (Frontend)
4. ë¬¸ì„œí™” (docstring) í•„ìˆ˜
5. ë³´ì•ˆ ê²€í†  í†µê³¼
```

### 6.2 ì„±ëŠ¥ ê¸°ì¤€
```yaml
# ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­
API Response Time: < 200ms (95 percentile)
Database Query Time: < 50ms (average)
Frontend Bundle Size: < 1MB (gzipped)
Memory Usage: < 512MB per service
```

### 6.3 ëª¨ë‹ˆí„°ë§ ê¸°ì¤€
```python
# ê° ê¸°ëŠ¥ì€ ë‹¤ìŒ ë©”íŠ¸ë¦­ì„ ì œê³µí•´ì•¼ í•¨:
1. ì„±ëŠ¥ ë©”íŠ¸ë¦­ (ì‘ë‹µì‹œê°„, ì²˜ë¦¬ëŸ‰)
2. ì—ëŸ¬ ë©”íŠ¸ë¦­ (ì—ëŸ¬ìœ¨, ì—ëŸ¬ íƒ€ì…)
3. ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ (ì‚¬ìš©ë¥ , ì „í™˜ìœ¨)
4. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ (CPU, ë©”ëª¨ë¦¬, DB)
```

---

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸ í…œí”Œë¦¿

ê° ê¸°ëŠ¥ ê°œë°œ ì‹œ ì‚¬ìš©í•  ì²´í¬ë¦¬ìŠ¤íŠ¸:

### ê°œë°œ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ìš”êµ¬ì‚¬í•­ ëª…í™•í™” ì™„ë£Œ
- [ ] ê¸°ìˆ  ìŠ¤íƒ í™•ì •
- [ ] ì•„í‚¤í…ì²˜ ì„¤ê³„ ê²€í† 
- [ ] API ëª…ì„¸ì„œ ì‘ì„±
- [ ] í…ŒìŠ¤íŠ¸ ê³„íš ìˆ˜ë¦½

### ê°œë°œ ì¤‘ ì²´í¬ë¦¬ìŠ¤íŠ¸  
- [ ] ì½”ë“œ ë¦¬ë·° ìˆ˜í–‰
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
- [ ] ë³´ì•ˆ ê²€í†  ìˆ˜í–‰

### ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] í”„ë¡œë•ì…˜ í™˜ê²½ í…ŒìŠ¤íŠ¸
- [ ] ë¡¤ë°± ê³„íš ìˆ˜ë¦½
- [ ] ëª¨ë‹ˆí„°ë§ ì„¤ì • ì™„ë£Œ
- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì™„ë£Œ
- [ ] íŒ€ ê³µìœ  ì™„ë£Œ

---

*ì´ ê¸°ìˆ  ëª…ì„¸ì„œëŠ” ê°œë°œ ì§„í–‰ì— ë”°ë¼ ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.*